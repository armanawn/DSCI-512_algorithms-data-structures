{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 512 Lab 3\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "rubric={mechanics:5}\n",
    "\n",
    "Follow the [general lab instructions](https://ubc-mds.github.io/resources_pages/general_lab_instructions/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: The Romeo and Juliet graph\n",
    "\n",
    "Consider this graph of the social network connections in _Romeo and Juliet_ (you can ignore the gray background and the labels for the families):\n",
    "\n",
    "![](romeo-and-juliet-undirected.png)\n",
    "\n",
    "Image attribution: the Romeo and Juliet graph, and inspiration, taken from [UW CSE 140](https://courses.cs.washington.edu/courses/cse140/13wi/homework/hw4/homework4.html) with permission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below creates a graph named `rj` corresponding to the Romeo and Juliet graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rj = nx.Graph()\n",
    "rj.add_nodes_from(['Nurse',\n",
    "                   # House of Capulet\n",
    "                   'Juliet', 'Tybalt', 'Capulet',\n",
    "\n",
    "                   'Friar Laurence',\n",
    "\n",
    "                   # House Montague\n",
    "                   'Romeo', 'Benvolio', 'Montague',\n",
    "\n",
    "                   # Ruling house of Verona\n",
    "                   'Escalus', 'Mercutio', 'Paris'\n",
    "                   ])\n",
    "\n",
    "rj.add_edges_from([('Juliet', 'Nurse'),\n",
    "                   ('Juliet', 'Tybalt'),\n",
    "                   ('Juliet', 'Capulet'),\n",
    "                   ('Juliet', 'Friar Laurence'),\n",
    "                   ('Juliet', 'Romeo'),\n",
    "\n",
    "                   ('Capulet', 'Tybalt'),\n",
    "                   ('Capulet', 'Escalus'),\n",
    "                   ('Capulet', 'Paris'),\n",
    "\n",
    "                   ('Romeo', 'Friar Laurence'),\n",
    "                   ('Romeo', 'Benvolio'),\n",
    "                   ('Romeo', 'Montague'),\n",
    "                   ('Romeo', 'Mercutio'),\n",
    "\n",
    "                   ('Montague', 'Benvolio'),\n",
    "                   ('Montague', 'Escalus'),\n",
    "\n",
    "                   ('Escalus', 'Mercutio'),\n",
    "                   ('Escalus', 'Paris'),\n",
    "                   ('Paris', 'Mercutio')\n",
    "                   ])\n",
    "nx.draw(rj, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(a) graphs warmup\n",
    "rubric={accuracy:1}\n",
    "\n",
    "Write a function `highest_degree` that takes in a graph and finds the vertex/vertices with the highest degree - in other words, the person with the largest number of friends. Your function should return a tuple with two elements:\n",
    "\n",
    "1. The maximum degree (int)\n",
    "2. All the nodes with that degree (set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, a proper docstring is required.\n",
    "\n",
    "Note: you can find the degree of a vertex using the following syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.degree(rj, \"Paris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and you can iterate through all nodes in a graph like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in rj.nodes():\n",
    "    print(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_degree, nodes = highest_degree(rj)\n",
    "assert nodes == {\"Romeo\", \"Juliet\"}\n",
    "assert max_degree == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(b) largest distance\n",
    "rubric={accuracy:4,quality:2}\n",
    "\n",
    "One interesting measure in a social network graph is the \"distance\" or number of \"degrees of separation\" between two people. This notion is used in academic research via the [ErdÅ‘s number](https://en.wikipedia.org/wiki/Erd%C5%91s_number) and in the film industry via the [Bacon number](https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon#Bacon_numbers). For example, in the above graph, the distance between Juliet and Romeo is 1, and the distance between Juliet and Paris is 2 (via Capulet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path_length(rj, \"Juliet\", \"Romeo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.shortest_path_length(rj, \"Juliet\", \"Paris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `largest_distance` to find the pair(s) of vertices with the largest distance (degree of separation). Your function should return a tuple with two elements:\n",
    "\n",
    "1. The maximum distance (int)\n",
    "2. All the pairs of nodes with that distance (set of tuples)\n",
    "\n",
    "Note: do not include pairs twice. For example, if `('Romeo', 'Juliet')` is in the set, don't also include `('Juliet', 'Romeo')`.\n",
    "\n",
    "Your function should work by iterating through all pairs of vertices. For each pair, it should compute the distance (degree of separation) between nodes using the function `nx.shortest_path_length` used above. Later, we'll try something else that will be better.\n",
    "\n",
    "Hint: It is easier to avoid the duplicates as you go. To do this, before adding a tuple like `(v, w)`, first check if you already have `(w, v)`, and if so, don't add `(v, w)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_distance(G):\n",
    "    \"\"\"\n",
    "    Finds the pairs of vertices with the highest degree of separation in the graph G.\n",
    "    Returns a tuple (max_distance, {node pairs with that distance})\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : networkx.classes.graph.Graph\n",
    "        a network graph\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    max_distance: int \n",
    "       the maximum connections separating nodes \n",
    "    node pairs with max degree distance: set \n",
    "        nodes with largest separation  \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> test = nx.Graph()\n",
    "    >>> test.add_nodes_from(['A', 'B', 'C', 'D'])\n",
    "    >>> test.add_edges_from([('A', 'B'), ('B', 'C'),  ('C', 'D'), ('A', 'D')])\n",
    "    >>> largest_distance(test)\n",
    "    (2, {('A', 'C'), ('B', 'D')})\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance_rj, pairs_rj = largest_distance(rj)\n",
    "assert max_distance_rj == 3\n",
    "assert len(pairs_rj) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nx.Graph()\n",
    "test.add_nodes_from(['A', 'B', 'C', 'D'])\n",
    "test.add_edges_from([('A', 'B'), ('B', 'C'),  ('C', 'D'), ('A', 'D')])\n",
    "max_distance_test, pairs_test = largest_distance(test)\n",
    "assert max_distance_test == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1(c)\n",
    "rubric={reasoning:2}\n",
    "\n",
    "Assuming that `nx.shortest_path_length` takes $O(V)$ time in the worst case, what is the worst case time complexity if your `largest_distance` function from the previous part? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: computing degrees of separation with BFS\n",
    "rubric={accuracy:7}\n",
    "\n",
    "Let's see if we can come up with a better way to find the largest distance between two nodes in a graph; that is, an approach with a better time complexity than what we saw in the previous part. \n",
    "\n",
    "Here is the reason why the previous approach is unnecessarily slow: in calling `nx.shortest_path_length` between pairs of nodes we do a bunch of redundant/repeated computation. For example, computing the distance between Nurse and Mercutio is fairly similar to finding the distance between Juliet and Mercutio, but we're doing it all from scratch for every pair of nodes.\n",
    "\n",
    "Below we provide a function `distance_BFS` that takes in a networkx `Graph` and two nodes, and uses breadth-first search (BFS) to compute the distance between the two nodes; in other words, it does the same thing as `nx.shortest_path_length`. The function returns -1 if the two nodes are not connected (whereas `nx.shortest_path_length` throws an error). The code here is similar to the BFS code from lecture, except that instead of only storing the nodes in the queue, we store tuples of the (node, distance) so that we can keep track of the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_BFS(G, node1, node2):\n",
    "    \"\"\" \n",
    "    Given a NetworkX Graph G, and start node node1 \n",
    "    and goal node node2, distance_BFS returns the\n",
    "    degree of separation between node1 and node2. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : networkx.classes.graph.Graph\n",
    "        the graph\n",
    "    node1 : str\n",
    "        first node\n",
    "    node2 : str \n",
    "        second node\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int \n",
    "        the distance between 2 nodes, if\n",
    "        they are not connected, returns -1\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> test = nx.Graph()\n",
    "    >>> test.add_nodes_from(['A', 'B', 'C', 'D'])\n",
    "    >>> test.add_edges_from([('A', 'B'), ('B', 'C'),  ('C', 'D'), ('A', 'D')])\n",
    "    >>> distance_BFS(test, 'A', 'C')\n",
    "    2\n",
    "    \"\"\"\n",
    "\n",
    "    queue = [(node1, 0)]\n",
    "    visited = {node1}\n",
    "\n",
    "    while queue:\n",
    "        vertex, distance = queue.pop(0)\n",
    "        if vertex == node2:\n",
    "            return distance\n",
    "\n",
    "        for neighbour in G.neighbors(vertex):\n",
    "            if neighbour not in visited:\n",
    "                queue.append((neighbour, distance + 1))\n",
    "                visited.add(neighbour)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(distance_BFS(rj, \"Juliet\", \"Romeo\")) == 1\n",
    "assert(distance_BFS(rj, \"Juliet\", \"Paris\")) == 2\n",
    "assert(distance_BFS(rj, \"Nurse\", \"Paris\")) == 3\n",
    "assert(distance_BFS(rj, \"Nurse\", \"Mercutio\")) == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rj2 = rj.copy()\n",
    "rj2.add_node(\"Santa Claus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(distance_BFS(rj2, \"Romeo\", \"Santa Claus\")) == -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to adapt/modify the above code to create a function that takes in a node and returns the furthest (largest distance) node. The changes to the above code are not that major - you shouldn't be rewriting it from scratch. I suggest you start by pasting in the body of `distance_BFS` and modifying it from there.\n",
    "\n",
    "Implementation hint/suggestion: recall that BFS explores the vertices in order of distance (neighbours, then neighbours of neighbours, etc.). Therefore, the distance and vertices that you want are the ones explored last. You can keep track of this in multiple ways. One possibility is to store the set of vertices for every distance. Then, when you are done the BFS, return the vertices corresponding to the largest distance. Another possible approach, which uses less storage, is to only keep track of the most recent (largest) distance and associated vertices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def furthest_from_node(G, node):\n",
    "    \"\"\" \n",
    "    Finds the maximum distance, and associated nodes, from the given input node in the graph G.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : networkx.classes.graph.Graph\n",
    "        the graph\n",
    "    node : str\n",
    "        the node\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple (int, set)\n",
    "        the first element is the largest distance\n",
    "        the second element is a set of the nodes that achieve this distance\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> test = nx.Graph()\n",
    "    >>> test.add_nodes_from(['A', 'B', 'C', 'D'])\n",
    "    >>> test.add_edges_from([('A', 'B'), ('B', 'C'),  ('C', 'D'), ('A', 'D')])\n",
    "    >>> furthest_from_node(test, 'A')\n",
    "    (2, {'C'})\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert furthest_from_node(test, 'A')[0] == 2\n",
    "assert furthest_from_node(test, 'A')[1] == {'C'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert furthest_from_node(rj, 'Nurse')[0] == 3\n",
    "assert furthest_from_node(rj, 'Nurse')[1] == {'Paris', 'Escalus', 'Mercutio', 'Benvolio', 'Montague'}\n",
    "\n",
    "assert furthest_from_node(rj, 'Juliet')[0] == 2\n",
    "assert furthest_from_node(rj, 'Nurse')[1] == {'Paris', 'Escalus', 'Mercutio', 'Benvolio', 'Montague'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: code timing\n",
    "\n",
    "Assuming you have implemented `furthest_from_node` above, the function `largest_distance_faster` below will call your `furthest_from_node` function and find the pair of nodes with the largest distance. The code isn't very pretty, but it should work the same way as your `largest_distance` from 1(b) - but faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_distance_faster(G):\n",
    "    \"\"\"\n",
    "    Finds the pairs of vertices with the highest degree of separation in the graph G.\n",
    "    Returns a tuple (max_distance, {node pairs with that distance})\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : networkx.classes.graph.Graph\n",
    "        a network graph\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    max_distance: int \n",
    "       the maximum connections separating nodes \n",
    "    node pairs with max degree distance: set \n",
    "        nodes with largest separation  \n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> test = nx.Graph()\n",
    "    >>> test.add_nodes_from(['A', 'B', 'C', 'D'])\n",
    "    >>> test.add_edges_from([('A', 'B'), ('B', 'C'),  ('C', 'D'), ('A', 'D')])\n",
    "    >>> largest_distance(test)\n",
    "    (2, {('A', 'C'), ('B', 'D')})\n",
    "    \"\"\"\n",
    "\n",
    "    overall_max_dist = 0\n",
    "    distances = dict()\n",
    "    for v in G.nodes():\n",
    "        max_dist, max_dist_nodes = furthest_from_node(G, v)\n",
    "\n",
    "        distances[v] = (max_dist, max_dist_nodes)\n",
    "        overall_max_dist = max(overall_max_dist, max_dist)\n",
    "    \n",
    "    node_pairs = set()\n",
    "    for v, output in distances.items():\n",
    "        output_dist, output_nodes = output\n",
    "        if output_dist == overall_max_dist:\n",
    "            for w in output_nodes:\n",
    "                if (w, v) not in node_pairs:\n",
    "                    node_pairs.add((v, w))\n",
    "    \n",
    "    return overall_max_dist, node_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert largest_distance_faster(test)[0] == 2\n",
    "assert largest_distance_faster(test)[1] == {('A', 'C'), ('B', 'D')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance, pairs = largest_distance(rj)\n",
    "assert max_distance == 3\n",
    "assert len(pairs) == 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(a)\n",
    "rubric={reasoning:2}\n",
    "\n",
    "What is the time complexity of `largest_distance_faster`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3(b)\n",
    "rubric={reasoning:6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a networkx function that generates graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladder = nx.generators.classic.ladder_graph(3)\n",
    "nx.draw(ladder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can change the size by changing its argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ladder = nx.generators.classic.ladder_graph(5)\n",
    "nx.draw(ladder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function to generate graphs, perform a timing experiment to time `largest_distance` (which you wrote) and `largest_distance_faster` (which I wrote, but which calls `furthest_from_node` that you wrote). Are the results consistent with the big-O running times we expected? Is `largest_distance_faster` indeed faster than `largest_distance`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Using Facebook data\n",
    "\n",
    "We will use some Facebook data, which is the file `facebook-links.txt` in the [datasets repository](https://github.ubc.ca/MDS-2020-21/datasets).\n",
    "\n",
    "Note: if you go to that file in the repo, and right-click \"Download\", and select Save File As (or similar), then you can get this file without cloning/downloading the whole datasets repo.\n",
    "\n",
    "The `facebook-links.txt` file is courtesy of the Max Planck Institute for Software Systems. Here is a slightly clarified version of the documentation for this file:\n",
    "\n",
    "> File `facebook-links.txt` contains a list of all of the user-to-user links from the Facebook New Orleans networks. These links are undirected on Facebook.\n",
    ">\n",
    "> Format: Each line contains two numeric user identifiers, meaning the second user appeared in the first user's friend list, and the first user appeared in the second user's friend list. Finally, the third column is a UNIX timestamp with the time of link establishment (if it could be determined, otherwise it is '\\N'). Note: a Unix timestamp is the number of seconds since January 1, 1970. You may ignore it in this assignment. \n",
    "\n",
    "\n",
    "The code below creates a graph named facebook from the Facebook data in file `facebook-links.txt`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_edges = pd.read_csv(\"facebook-links.txt\", sep='\\t')\n",
    "facebook_edges.columns = [\"from\", \"to\", \"timestamp\"]\n",
    "facebook_edges.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_graph = nx.convert_matrix.from_pandas_edgelist(\n",
    "    facebook_edges, \"from\", \"to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(facebook_graph.nodes()) == 63731\n",
    "assert len(facebook_graph.edges()) == 817090"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(a)\n",
    "rubric={viz:1}\n",
    "\n",
    "Using your plotting skills from DSCI 531, create a histogram of the node degrees in this graph. For example, how many nodes have degree 1, how many nodes have degree 2, etc. Make sure you use enough bins so you can see the general shape of things.\n",
    "\n",
    "Note: you an get the degree of a node with `graph.degree(node)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(b)\n",
    "rubric={accuracy:1}\n",
    "\n",
    "To summarize the histogram further, find the mean, median, and mode of the vertex degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(c)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "Although all nodes in this dataset have at least one friend, the graph is not _connected_; that is, for two nodes A and B, there is not necessarily a path from A to B. A subset of nodes that are connected is called a _connected component_. We can get the connected components using `nx.connected_components(graph)` in networkx."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you understand what `connected_components` returns, let's take this example graph from lecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disconnected = nx.Graph()\n",
    "\n",
    "disconnected.add_edge(\"A\", \"B\")\n",
    "disconnected.add_edge(\"A\", \"C\")\n",
    "disconnected.add_edge(\"D\", \"C\")\n",
    "disconnected.add_edge(\"B\", \"C\")\n",
    "\n",
    "disconnected.add_edge(\"E\", \"F\")\n",
    "\n",
    "nx.draw(disconnected, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the output of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(nx.connected_components(disconnected))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it returns a generator (casted to a list above) of sets, each containing a connected component in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the number of vertices in these connected components from the Facebook graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = nx.connected_components(facebook_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_verts = [len(cc) for cc in components]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(num_verts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1-2 sentences, briefly discuss the result above in the context of the social network. What is going on here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (challenging) 4(d)\n",
    "rubric={reasoning}\n",
    "\n",
    "Below we grab the largest connected component of the Facebook graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connected_components = nx.connected_components(facebook_graph)\n",
    "fb_largest_cc_nodes = next(connected_components)\n",
    "fb_largest_cc = facebook_graph.subgraph(fb_largest_cc_nodes).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the number of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fb_largest_cc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of this lab has been about finding the pair of nodes with the largest distance between them. Let's say you wanted to find the largest distance between any pair of nodes in the largest connected component of the Facebook graph. With such a large graph, this might take a long time. Using your timing analysis from 3(b) above, estimate how long this would take using `largest_distance_faster`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(e)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "How many bytes do you think the dense (not sparse) form of the Facebook adjacency matrix would take, if each element takes 8 bytes? (If you try it, you may well run out of memory)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4(f)\n",
    "rubric={reasoning:1}\n",
    "\n",
    "How many bytes do you think the sparse form of the Facebook adjacency matrix would take, if each element takes 8 bytes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (challenging) Exercise 5: assessing virality\n",
    "rubric={reasoning}\n",
    "\n",
    "Everyone wants their video or app to \"go viral\". This can occur by something spreading through a social network. Here, we will model virality as follows: \n",
    "\n",
    "1. pick some virality coefficient $\\xi\\in (0,1)$\n",
    "2. select one person (node) at random to be initially \"infected\"\n",
    "3. each currently infected person loses interest with probability $\\alpha$ and becomes _permanently_ un-infected. By default we'll use $\\alpha=0.01$.\n",
    "4. for each infected person, each neighbour in the graph becomes infected with probability $\\xi$. Note: if multiple neighbours of an un-infected node are infected, repeat this step multiple times. For example, if Mercutio and Paris like _Gangnam Style_, then Escalus has two chances of being infected at the current time step. Mathematically, the probability of infection is $1-(1-\\xi)^2 = 2\\xi-\\xi^2$, but you don't need to calculate this in your code because you can just repeatedly try to infect the person.\n",
    "5. repeat steps 3-4 some number of times, by default $1000$. \n",
    "\n",
    "Write a function implementing this model. Your function should return a list/array of the proportion of people infected at each iteration. Using the Facebook data set (or a subgraph if the code is too slow), explore some or all of the following questions:\n",
    "\n",
    "1. Investigate how the number of infected people proceeds as a function of time: what is the general shape you observe? Is it consistent across runs of the simulation?\n",
    "2. Report the _maximum_ proportion of your population that was infected at any given time. Try this for a couple values of $\\xi$ and investigate how the maximum proportion of infected people depends on $\\xi$. Note: For a given value of $\\xi$ you will need to run several simulations and average the results to reduce noise. \n",
    "3. Do your results depend significantly on the connectivity of the graph? For example, if you randomly remove half of the edges in the Facebook graph (be careful not to delete any vertices in the process!), what is the effect on the virality? \n",
    "\n",
    "Note: this model for virality is similar to rudimentary models of how diseases spread across populations. See [here](https://en.wikipedia.org/wiki/Mathematical_modelling_of_infectious_disease#The_SIR_model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.6 ('dsci512')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "833530e805897aab5e7a30ee530b0bcb4cd19373b840f29eae5897b61b26002e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
